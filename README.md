# Extracting Temporal Narrative Components with Large Language Models
## An evaluation of different techniques and models  

> Daniel D. Stuiver (13197843)  
> Bachelor Thesis, Information Science, University of Amsterdam, Semester 2 2024–2025

---

## Overview

This repository contains all materials for the Bachelor thesis **“Extracting Temporal Narrative Components with Large Language Models”**, in which we investigate the ability of modern LLMs (zero-, one- and few-shot) to automatically extract temporal elements (order, duration, frequency, etc.) from product reviews, compare their performance across models, and evaluate against a manually annotated gold standard using BERT-based similarity measures and classification metrics.

<!-- **Abstract**  
This thesis investigates the ability of Large Language Models (LLMs) to extract temporal
narrative components from user-generated Amazon product reviews. Drawing on Genette’s
framework of order, duration, frequency and additional temporal categories, a balanced subset
of 100 “Home & Kitchen” reviews was manually annotated according to a bespoke codebook.
Both zero-shot and one-shot prompting strategies were evaluated, with zero-shot proving more
precise (micro-F1 = 0.146 vs. 0.138). Five LLMs (models from the GPT-family, Claude Sonnet
4, and Gemini 2.5 Pro) were then compared: GPT-4o achieved the best detection balance (P
= 0.25, R = 0.42, F1 = 0.31) and 45% classification accuracy. Results highlight LLMs’ basic
temporal awareness but underscore the need for enhanced prompting and task-specific fine-
tuning to reduce false positives and improve nuanced temporal classification. -->

---


